---
title: 'PC2 - Minería de Datos'
author: "Francisco Andrade, Fernando Cortés, Ana Rosa Cajavilca y Anilda Guevara"
date: '`r Sys.Date()`'
output:
  html_document:
    number_sections: false
    toc: true
    fig_width: 7
    fig_height: 4.5 
    highlight: tango
---

<style>
body {
text-align: justify}
</style>

---

# 1. Esta pregunta debe responderse utilizando el conjunto de datos *Weekly*, que es parte del paquete ISLR.

---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo=TRUE, error=FALSE)
```


## a. Produzca algunos resúmenes numéricos y gráficos de los datos semanales. ¿Parece que hay algún patrón?

El dataset Weekly presenta el porcentaje semanal de rendimientos para el índice de acciones Standard & Poor's (S&P) 500. El índice se basa en la capitalización bursátil de 500 grandes empresas que cotizan en las bolsas de Nueva York (New York Stock Exchange abreviado NYSE) o la National Association of Securities Dealers Automated Quotation (NASDAQ), que es la segunda bolsa de valores automatizada y electrónica más grande de Estados Unidos. 

El dataset Weekly contiene 1089 observaciones semanales tomadas durante 21 años, desde 1990 hasta el 2010, con las siguientes 9 variables:

* Year: El año en que se registró la observación.
* Lag1: Porcentaje de retorno de la semana anterior
* Lag2: Porcentaje de retorno para 2 semanas previas.
* Lag3: Porcentaje de retorno para las 3 semanas anteriores.
* Lag4: Porcentaje de retorno por 4 semanas previas.
* Lag5: Porcentaje de retorno durante las 5 semanas anteriores.
* Volumen: Volumen de acciones negociadas (número promedio de acciones diarias negociadas en miles de millones)
* Today: Porcentaje de retorno para esta semana.
* Direction: Un factor con niveles abajo y arriba que indica si el mercado tuvo un rendimiento positivo o negativo en una semana determinada.

```{r message=FALSE, warning=FALSE, , include=TRUE}
library(ISLR)
library(ggplot2)
library(knitr)
library(skimr)
library(ggpubr)
library(reshape2)
library(knitr)
library(dplyr)
library(data.table)
library(MASS)
library(class)
library(scatterplot3d)
library(GGally)
library(corrplot)
data("Weekly")
head(Weekly)
```

**A continuación mostramos un pequeño descriptivo de las variables:**

```{r message=FALSE, warning=FALSE, , include=TRUE}
# summary(Weekly)
skim(Weekly)
```

Se observa que la data contiene información entre los años 1990 a 2010, siendo las medias y los percentiles de las variables "Lag" y "Today" bastante similares entre si (0.15 de media), lo cual indicara que los rendimientos entre semanas tienen una distribución bastante parecida. Para identificar algún patrón entre las variables del dataset analizaremos las correlaciones. 

* **Análisis de correlación**

```{r message=FALSE, warning=FALSE, , include=TRUE}
cor_matrix <- round(cor(Weekly[,-9], method = "pearson" ), digits = 2)
cor_matrix[upper.tri(cor_matrix, diag = TRUE)] <- ""
as.data.frame(cor_matrix)
```

La matriz de correlación indicaría una nula correlación entre las variables "Lag" con "Today", lo cual indicaría que los rendimientos pasados no influyen en el rendimiento presente. Sin embargo, si se observa una alta correlación positiva entre "Year" con "Volume" esto puede interpretarse como que el volumen de acciones negociadas se ha incrementado a lo largo de los años, lo que se observa en el siguiente gráfico de serie de tiempo:

```{r message=FALSE, warning=FALSE, , include=TRUE}
volumetimeseries <- ts(Weekly$Volume, frequency=52, start=c(1990,1))
plot.ts(volumetimeseries)
```

* **Distribuciones de las variables "Lag", "Today" y "Volume" según "Direction"**

Ahora, verificaremos las distribuciones de todas las variables según la variable respuesta "Direction" a fin de visualizar si existen distribuciones distintas entre poblaciones con diferentes direcciones:

Distribuciones de las variables según "Direction - Down":

```{r message=FALSE, warning=FALSE, , include=TRUE}
x1.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Lag1)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

x2.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Lag2)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

x3.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Lag3)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

x4.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Lag4)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

x5.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Lag5)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

x6.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Today)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

x7.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(Volume)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")

ggarrange(x1.down,x2.down,x3.down,x4.down,x5.down,x6.down,x7.down, nrow = 3, ncol = 3)

```

Distribuciones de las variables según "Direction - Up":

```{r message=FALSE, warning=FALSE, , include=TRUE}
x1.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Lag1)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

x2.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Lag2)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

x3.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Lag3)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

x4.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Lag4)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

x5.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Lag5)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

x6.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Today)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

x7.up=Weekly %>%
  filter(Direction=="Up") %>%
  ggplot(aes(Volume)) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")

ggarrange(x1.up,x2.up,x3.up,x4.up,x5.up,x6.up,x7.up, nrow = 3, ncol = 3)

```

De acuerdo a los histogramas presentados, se observa que existe una especie de normalidad en la distribución en la mayoría de variables "Lag". La cual deja de estar presente según "Direction" principalmente en las variables "Volume" y "Today". Para verificar la normalidad del conjunto de datos, utilizaremos el qqplot para cada una de las variables y veremos si caen dentro del intervalo de confianza de los cuantiles de una normal:

* **Test de Normalidad de las variables - qqplot**

```{r message=FALSE, warning=FALSE, , include=TRUE}
library(car)
par(mfrow = c(1, 2))
for(i in 2:3){
  qqPlot((Weekly %>%
            filter(Direction=="Down"))[ , i])
}
```
```{r message=FALSE, warning=FALSE, , include=TRUE}
par(mfrow = c(1, 2))
for(i in 4:5){
  qqPlot((Weekly %>%
            filter(Direction=="Down"))[ , i])
}
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
par(mfrow = c(1, 2))
for(i in 6:7){
  qqPlot((Weekly %>%
            filter(Direction=="Down"))[ , i])
}
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
par(mfrow = c(1, 2))
for(i in 8){
  qqPlot((Weekly %>%
            filter(Direction=="Down"))[ , i])
}
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
library(car)
par(mfrow = c(1, 2))
for(i in 2:3){
  qqPlot((Weekly %>%
            filter(Direction=="Up"))[ , i])
}
```
```{r message=FALSE, warning=FALSE, , include=TRUE}
par(mfrow = c(1, 2))
for(i in 4:5){
  qqPlot((Weekly %>%
            filter(Direction=="Up"))[ , i])
}
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
par(mfrow = c(1, 2))
for(i in 6:7){
  qqPlot((Weekly %>%
            filter(Direction=="Up"))[ , i])
}
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
par(mfrow = c(1, 2))
for(i in 8){
  qqPlot((Weekly %>%
            filter(Direction=="Up"))[ , i])
}
```

Se puede apreciar que en todas las gráficas hay observaciones que salen fuera de los intervalos de confianza, por lo que aparentemente no deberían ser distribuciones normales especialmente por las colas. Lo comprobaremos con el test de Shapiro Wilk.

* **Test de Normalidad de las variables - Shapiro Wilk**

```{r message=FALSE, warning=FALSE, , include=TRUE}
#Contraste de normalidad Shapiro-Wilk para cada variable en cada dirección
Weekly_tidy <- melt(Weekly[,-1], value.name = "valor")
Weekly_tidy=data.table(Weekly_tidy %>% group_by(Direction, variable) %>% 
summarise(p_value_Shapiro.test = shapiro.test(valor)$p.value));Weekly_tidy
```

Se observa que el p-value en todas variables según "Direction" es menor al nivel de significación de 0.05 por lo cual se rechaza la hipótesis de normalidad de las variables.


## b. Use el conjunto de datos completo para realizar una regresión logística con Direction como la respuesta y las cinco variables lag más el "Volume" como predictores. Use la función summary para imprimir los resultados. ¿Alguno de los predictores parece ser estadísticamente significativo? Si es así, ¿cuáles?

Antes de realizar el ajuste logístico, convertimos la variable de respuesta "Direction" en dicotómica:

```{r message=FALSE, warning=FALSE, , include=TRUE}
contrasts(Weekly$Direction)
``` 

Aplicamos la regresión logística con la función "glm" con link "binomial", para predecir la variable "Direction" considerando como covariables a las variables "Lag" y "Volume", obteniéndose que sólo la variable "Lag 2" es significativa. Además, dado que el coeficiente estimado respecto a dicha variables es positivo, indica que si el rendimiento subió hace dos semanas, es más probable que la dirección del rendimiento sea "Up".

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo_logistico <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, family = "binomial")
summary(modelo_logistico)
exp(coef(modelo_logistico))
``` 

## c. Calcule e interprete la matriz de confusión de las predicciones correctas obtenido por una regresión logística.

* **Predicciones de la regresión logística ajustada en (b) con data total**

Con el modelo ajustado en (b) se realizan predicciones con la función "predict". Mostramos la predicción de las 6 primeras observaciones

```{r}
predicciones <- predict(object = modelo_logistico, type = "response")
head(predicciones)
```

Para hallar el punto de corte óptimo comenzamos graficando la curva ROC

```{r warning = FALSE, message = FALSE}
library(pROC)
plot(roc(as.numeric(Weekly$Direction)-1, predicciones))
roc(as.numeric(Weekly$Direction)-1, predicciones)
```

Se puede apreciar que el nivel de diferenciación es bastante bajo (0.55 AUC), sacaremos la distribución de Down y Up para ver en qué percentil de las predicciones se asemeja a esa distribución:

```{r}
prop.table(table(Weekly[ , 9]))
```

Obtenemos el cuantil correspondiente a 0.444444

```{r}
(q <- quantile(predicciones, p = 0.4444444))
```

Utilizamos este valor como punto de corte

```{r message=FALSE, warning=FALSE, , include=TRUE}
prediccion <- data.frame(probabilidad = predicciones, clase = rep(NA,length(predicciones)))
prediccion[prediccion$probabilidad < q,"clase"] <- "Down"
prediccion[prediccion$probabilidad > q,"clase"] <- "Up"
head(prediccion)
``` 

Matriz de confusión del modelo logístico con data total:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = Weekly$Direction,clase_predicha = prediccion$clase)
``` 

Accuracy del modelo logístico con data total:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de acierto del modelo es",mean(prediccion$clase == Weekly$Direction),"lo cual indicaría un bajo nivel de acierto en la predicción")
``` 

Error de predicción del modelo logístico con data total:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de error de predicción del modelo es",mean(prediccion$clase != Weekly$Direction))
``` 

Sensitividad y Especificidad:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La sensitividad del modelo es:",(352/(352+253)))
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La especificidad del modelo es:",(231/(231+253)))
``` 

Estos indicadores nos dicen que efectivamente el modelo no es bueno para realizar predicciones, pues prácticamente está asignando aleatoriamente la dirección Up o Down. Sin embargo, debemos tener en cuenta que las predicciones fueron realizadas con un modelo con variables no significativas y con la totalidad de las observaciones.

## d. Ahora ajuste el modelo de regresión logística utilizando un período de datos de capacitación de 1990 a 2008, con Lag2 como el único predictor. Calcule la matriz de confusión de las predicciones correctas para los datos retenidos (es decir, los datos de 2009 y 2010).

```{r message=FALSE, warning=FALSE, , include=TRUE}
train_data <- Weekly[Weekly$Year < 2009,]
test_data <- Weekly[!(Weekly$Year < 2009),]
``` 

* **Ajuste de modelo logístico con data "train"**

A continuación se muestran los coeficietes de un modelo logístico ajustado con la variable Lag2 en la data de entrenamiento, resultando los siguientes coefcientes de regresión.  

```{r message=FALSE, warning=FALSE, , include=TRUE}
# Se crea el modelo de regresión logística
modelo <- glm(Direction ~ Lag2, data = train_data, family = "binomial")
summary(modelo)
``` 

A continuación se muestran las prediciones de las seis primeras observacinoes realizadas en data test. El punto de corte utilizado fue el mismo que en la parte (c).
```{r message=FALSE, warning=FALSE, , include=TRUE}
# Se realizan las predicciones para el set de datos no empleado en la creación
# del modelo
predicciones2 <- predict(object = modelo, newdata = test_data, type = "response")
predicciones2[predicciones2 > q] <- "Up"
predicciones2[predicciones2 != "Up"] <- "Down"
head(predicciones2)
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = test_data$Direction,clase_predicha = predicciones2)
``` 

Accuracy del modelo logístico:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de acierto del modelo es",mean(predicciones2 == test_data$Direction),"lo cual indicaría un moderado nivel de acierto en la predicción")
``` 

Error de predicción del modelo logístico:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de error de predicción del modelo es",mean(predicciones2 != test_data$Direction), "menor a lo observado en el modelo ajustado en (c)")
``` 

Sensitividad y Especificidad:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La sensitividad del modelo es:",(34/(34+27)))
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La especificidad del modelo es:",(21/(21+22)))
``` 

Los resultados de este modelo son bastante parecidos al de (c).

## e. Repetir (d) usando LDA


* **Modelo LDA**

Se realizó el modelo LDA en data train, y se realizaron las predicciones en data test con el modelo entrenado, obteniéndose las siguientes predicciones en las 6 primeras observaciones, el punto de corte que utiliza el paquete "lda" por default es 0.5:

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo_lda <- lda(Direction ~ Lag2, data = train_data)
predicciones_lda <- predict(object = modelo_lda, test_data)
head(predicciones_lda$class)
``` 

Matriz de confusión del modelo LDA:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real =  test_data$Direction,clase_predicha = predicciones_lda$class)
``` 

Accuracy del modelo LDA

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de acierto del modelo es",mean(predicciones_lda$class == test_data$Direction),"lo cual indicaría un moderado nivel de acierto en la predicción y es similar al obtenido en el modelo logístico en (d)")
``` 

Error de predicción del modelo LDA:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de error de predicción del modelo es",mean(predicciones_lda$class != test_data$Direction), "menor a lo observado en el modelo ajustado en (c) y similar a lo obtenido con el modelo logístico en (d)")
``` 

Sensitividad y Especificidad:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La sensitividad del modelo es:",(56/(56+5)))
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La especificidad del modelo es:",(9/(9+34)))
``` 

A diferencia de los modelos presentados anteriormente, este modelo predice aparentemente de forma correcta la dirección "Up", sin embargo es porque a la mayoría de predicciones les está asignando este valor.

## f. Repetir (d) usando QDA

* **Modelo QDA**

Se realizó el modelo QDA en data train, y se realizaron las predicciones en data test con el modelo entrenado, obteniéndose las siguientes predicciones en las 6 primeras observaciones, el punto de corte que utiliza el paquete "qda" por default es 0.5:

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo_qda <- qda(Direction ~ Lag2, data = train_data)
predicciones_qda <- predict(object = modelo_qda, test_data)
head(predicciones_qda$class)
``` 

Matriz de confusión del modelo QDA:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real =  test_data$Direction,clase_predicha = predicciones_qda$class)
``` 

En este caso se observa que el modelo QDA sólo predice la dirección "Up" por lo que es una mala predicción.

**Accuracy del modelo QDA**

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de acierto del modelo es",mean(predicciones_qda$class == test_data$Direction),"lo cual indicaría un bajo nivel de acierto en la predicción y menor a los mdelos vistos en los puntos anteriores")
``` 

**Error de predicción del modelo**

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de error de predicción del modelo es",mean(predicciones_qda$class != test_data$Direction), "mayor a los modelos observados en (c) y (d)")
``` 

Sensitividad y Especificidad:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La sensitividad del modelo es:",(61/(61+0)))
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La especificidad del modelo es:",(0/(0+43)))
``` 

El modelo QDA no logra pronosticar los rendimientos con dirección "Down".

## g. Repita (d) usando KNN con K = 1

* **Modelo KNN, con K=1**

Se realizó el modelo KNN con k igual a 1 en data train, y se realizaron las predicciones en data test con el modelo entrenado, obteniéndose las siguientes predicciones en las 6 primeras observaciones:

```{r message=FALSE, warning=FALSE, , include=TRUE}
# En caso de empate entre los vecinos, se elige uno aleatoriamente.Esto influye en la reproducibilidad.
prediccion_knn2 <- knn(train = matrix(train_data[, "Lag2"]),
                       test = matrix(test_data[, "Lag2"]) ,
                       cl = train_data[,"Direction"], k = 1 )
head(prediccion_knn2)
``` 

Matriz de confusión con modelo KNN, con K=1:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = test_data$Direction,clase_predicha = prediccion_knn2)
``` 

Accuracy del modelo KNN con k=1:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de acierto del modelo es",mean(prediccion_knn2 == test_data$Direction),"lo cual indicaría un muy bajo nivel de acierto en la predicción y menor a los modelos de regresión logística y LDA")
``` 

Error de predicción del modelo KNN con K=1:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "El % de error de predicción del modelo es",mean(prediccion_knn2 != test_data$Direction), "mayor a los modelos antes observados")
``` 

Sensitividad y Especificidad:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La sensitividad del modelo es:",(32/(32+29)))
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste( "La especificidad del modelo es:",(21/(21+22)))
``` 

Los resultados de este modelo son bastante parecidos a los que se obtenían en los puntos (c) y (d). Sin embargo, el modelo igual no performa bien.

## h. ¿Cuál de estos métodos parece proporcionar los mejores resultados en esta información?

Si utilizamos sólo como indicador medición al "Accuracy", diríamos que el LDA, sin embargo este valor alto se debe a que asigna gran cantidad de observaciones con el valor UP y también comete bastantes errores por lo mismo. Por ello, balanceando junto con la especificidad y sensitividad, el mejor modelo sería el de regresión logística.

## i. Experimente con diferentes combinaciones de predictores, incluidas posibles transformaciones e interacciones, para cada uno de los métodos. Informe las variables, el método y la matriz de confusión asociada que parece proporcionar los mejores resultados en los datos extendidos. Tenga en cuenta que también debe experimentar con valores para K en el clasificador KNN.

* **Modelo Logístico con interacción**

Al utilizar una interacción entre Lag1 y Lag2 no se obtuvieron coeficientes con un p-value menor a 0.05 sino de .0.09 y 0.07. Se preocede a realizar predicciones con la data de test y la respectiva evaluación. 

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo.inter.glm <- glm(Direction ~ Lag1*Lag2, data = train_data, family = "binomial")
summary(modelo.inter.glm)
prediccon.inter.glm <- predict(object = modelo.inter.glm, newdata = test_data, type = "response")
prediccon.inter.glm[prediccon.inter.glm > 0.5] <- "Up"
prediccon.inter.glm[prediccon.inter.glm != "Up"] <- "Down"
``` 

Matriz de confusión del modelo logístico con interacción:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = test_data$Direction,clase_predicha = prediccon.inter.glm)
``` 

Indicadores de Accuracy y test de error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de aciertos
paste("El % de aciertos del modelo es:", mean(prediccon.inter.glm == test_data$Direction),"lo cual indicaría un nivel moderardo en acertar las predicciones, este resultado es un menor al obtenido con el modelo logístico en (d)")
``` 


```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de errores
paste("El % de error de predicción del modelo es", mean(prediccon.inter.glm != test_data$Direction), "un poco menor a lo observado en el modelo ajustado en (c) y mejor a lo obtenido con el modelo logístico en (d)")
```

* **Modelo LDA con interacción**

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo.inter.lda <- lda(Direction ~ Lag1*Lag2, data = train_data); modelo.inter.lda
predicciones_lda <- predict(object = modelo.inter.lda, test_data)
```

Matriz de confusión del modelo LDA con interacción:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real =  test_data$Direction,clase_predicha = predicciones_lda$class)
```

Indicadores de Accuracy y test de error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste("El % de acierto de predicción del modelo es", mean(predicciones_lda$class == test_data$Direction), "el mismo resultado del punto anterior, menor a lo observado en el modelo ajustado en (c) y mejor a lo obtenido con el modelo logístico en (d)")
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste("El % de error de predicción del modelo es", mean(predicciones_lda$class != test_data$Direction), "el mismo resultado del punto anterior, un poco menor a lo observado en el modelo ajustado en (c) y mejor a lo obtenido con el modelo logístico en (d)")
```

* **Modelo QDA con interacción**

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo.inter.qda <- qda(Direction ~ Lag1*Lag2, data = train_data);modelo.inter.qda
predicciones_qda <- predict(object = modelo.inter.qda, test_data)
``` 

Matriz de confusión de modelo QDA con interacción:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real =  test_data$Direction,clase_predicha = predicciones_qda$class)
``` 

Indicadores de Accuracy y test de error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste("El % de acierto de predicción del modelo es", mean(predicciones_qda$class == test_data$Direction), "menor resultado del punto anterior, a lo observado en el modelo ajustado en (c) y en (d)")
``` 

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste("El % de error de predicción del modelo es", mean(predicciones_qda$class != test_data$Direction), "mejor que el resultado del punto anterior, (c), (d), (e) y (f)")
``` 

* **Modelo KNN con K=6 con interacciones**

```{r message=FALSE, warning=FALSE, , include=TRUE}
# k = 6
set.seed(604)
train_data$Lag1Lag2 <- train_data$Lag1*train_data$Lag2
test_data$Lag1Lag2 <- test_data$Lag1*test_data$Lag2
prediccion_knn2 <- knn(train = train_data[,c("Lag1", "Lag2","Lag1Lag2")],
                       test = test_data[,c("Lag1", "Lag2","Lag1Lag2")] ,
                       cl = train_data[,"Direction"], k = 6)
```

Matriz de confusión de modelo KNN con K = 6 con interacciones:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_predicha = prediccion_knn2, clase_real = test_data$Direction)
```

Indicadores de Accuracy y test de error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de aciertos
paste("El % de acierto de predicción del modelo es", mean(prediccion_knn2 == test_data$Direction), "mejor que el resultado anterior")
```


```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de errores
paste("El % de error de predicción del modelo es",  mean(prediccion_knn2 != test_data$Direction), "menor al del resultado anterior")
```

* **Modelo logístico con transformación de variable "Volume"**

Histograma de variable "Volume" transformada (utilizando logaritmo):

```{r message=FALSE, warning=FALSE, , include=TRUE}
library(dplyr)
x7.down=Weekly %>%
  filter(Direction=="Down") %>%
  ggplot(aes(log(Volume))) +
  geom_histogram(aes(y=..density..), bins = 20, colour="red", fill="white")+
  geom_density(alpha=0.2, fill="#FF6655",position = "stack")+
  ggtitle("Log Volume según Dirección Down")

x7.up=Weekly %>%
  filter (Direction=="Up")%>%
  ggplot(aes(log(Volume))) +
  geom_histogram(aes(y=..density..), bins = 20, colour="blue", fill="white")+
  geom_density(alpha=0.2, fill="#141CFF",position = "stack")+
  ggtitle("Log Volume según Dirección Up")

ggarrange(x7.down,x7.up, nrow = 1, ncol = 2)
```

Modelo con variable transformada: 
```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + log(Volume), data = Weekly, family = "binomial")
summary(modelo)
```

```{r message=FALSE, warning=FALSE, , include=TRUE}
# Se realizan las predicciones para el set de datos no empleado en la creación
# del modelo
predicciones2 <- predict(object = modelo, newdata = test_data, type = "response")
# Se considera como threshold de clasificación el 0.5
predicciones2[predicciones2 > 0.5] <- "Up"
predicciones2[predicciones2 != "Up"] <- "Down"
```

Matriz de confusión de modelo con variable transformada:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_predicha = predicciones2, clase_real = test_data$Direction)
```

Indicadores de Acurracy y test de error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de aciertos
paste("El % de acierto de predicción del modelo es",  mean(predicciones2 == test_data$Direction), "similar a los otros resultados")
```


```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de errores
paste("El % de error de predicción del modelo es",mean(predicciones2 != test_data$Direction),  "similar a los otros resultados")
```


En el siguiente cuadro se observa un resumen de los resultados de la capacidad de predecir aciertos y errores de los diferentes modelos los cuales no muestran un buen desempeño. El modelo knn con interacción presenta mejores resulados para los aciertos y QDA con interacción  es el que más porcentaje de error presenta.

```{r message=FALSE, warning=FALSE, , include=TRUE}
# consolidado


a.01<-mean(prediccon.inter.glm == test_data$Direction)
e.01<-mean(prediccon.inter.glm != test_data$Direction)
# Modelo Logístico con interacción
a.1<-cbind(a.01,e.01)

a.02<-mean(predicciones_lda$class == test_data$Direction)
e.02<-mean(predicciones_lda$class != test_data$Direction)
# Modelo LDA con interacción
a.2<-cbind(a.02,e.02)

a.03<-mean(predicciones_qda$class == test_data$Direction)
e.03<-mean(predicciones_qda$class != test_data$Direction)
# Modelo QDA con interacción
a.3<-cbind(a.03,e.03)

a.04<-mean(prediccion_knn2 == test_data$Direction)
e.04<-mean(prediccion_knn2 != test_data$Direction)
# Modelo KNN con K=6 con interacciones
a.4<-cbind(a.04,e.04)


a.05<-mean(predicciones2 == test_data$Direction)
e.05<-mean(predicciones2 != test_data$Direction)
# Modelo logístico con transformación de variable “Volume”
a.5<-cbind(a.05,e.05)

b1<-rbind(a.1,a.2,a.3,a.4,a.5)
colnames(b1)<-c("% acierto","% error")
rownames(b1)<-c("log.con.interacción","lda.con.interacción","qda.con.interacción","knn.con.interacción","log.con.transf.variable")
b1
```



---

# 2. En este problema, desarrolle un modelo para predecir si un automóvil dado obtiene un millaje de gasolina alto o bajo en función del conjunto de datos Auto del paquete ISLR.

---

## a. Cree una variable binaria, mpg01, que contenga un 1 si mpg contiene un valor por encima de su mediana, y un 0 si mpg contiene un valor por debajo de su mediana. Puede calcular la mediana utilizando la función median(). Tenga en cuenta que puede resultarle útil utilizar la función data.frame() para crear un único conjunto de datos que contenga tanto mpg01 como las otras variables de Auto.

```{r message=FALSE, warning=FALSE, , include=TRUE}
Auto <- data.table(Auto)
mediana.mpg <- median(Auto$mpg)
Auto[ , mpg1 := as.factor(ifelse(mpg > mediana.mpg, 1, 0))]
Auto[sample(1:nrow(Auto), 15), ]
```

## b. Explore los datos gráficamente para investigar la asociación entre mpg01 y las otras características. ¿Cuál de las otras características parece ser más útil para predecir mpg01? Los diagramas de dispersión y los diagramas de caja pueden ser herramientas útiles para responder a esta pregunta. Describe tus hallazgos.

* Matriz de correlación

```{r message=FALSE, warning=FALSE, , include=TRUE}
M <- cor(Auto[ , -c(9, 10)])
corrplot(M, method = "number", type = "upper")
```

En la gráfica de matriz de correlación se observa una alta correlación negativa entre las variables "cylinders", "displacement", "horsepower" y "weight" con la variable "mpg", que a su vez representa a la variable binaria de respuesta "mpg1", es decir, todas estas variables al tener una relación lineal negativa podrían ayudar a predecir a "mpg1"; sin embargo, estas variables tienen una alta correlación positiva entre si, por lo cual antes de ingresar al modelo nos tocará elegir una de ellas para el modelamiento.

Por otro lado las variables "year" y "origin" tienen una moderada correlación positiva con "mpg"; sin embargo "origin" tiene una correlación positiva con la variable "cylinders", "displacement" y "weight", por lo cual si ingresa al modelado no debe estar las variables mencionadas en la ecuación.

Para analizar y elegir a la(s) mejor(es) variable(s) que ayuden a predecir "mpg1", teniendo en cuenta sus correlaciones, utilizaremos digramas de dispersión, de cajas y gráficos de desensidad.

* Diagramas de dispersión

```{r message=FALSE, warning=FALSE, , include=TRUE}
p1=Auto %>%
  ggplot(aes(mpg, cylinders, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "cylinders")

p2=Auto %>%
  ggplot(aes(mpg, displacement, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "displacement")

p3=Auto %>%
  ggplot(aes(mpg, horsepower, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "horsepower")

p4=Auto %>%
  ggplot(aes(mpg, weight, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "weight")

p5=Auto %>%
  ggplot(aes(mpg, acceleration, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "acceleration")

p6=Auto %>%
  ggplot(aes(mpg, year, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "year")

p7=Auto %>%
  ggplot(aes(mpg, origin, colour = mpg1)) +
  geom_point(size = 1) +
  labs(x = "mpg", y = "origin")

ggarrange(p1,p2,p3,p4,p5,p6,p7, nrow = 3, ncol = 3)

```

En los gráficos de dispersión se verifica visualmente las correlaciones entre "mpg1" con las variables "cylinder","displacement","horsepower", "weight", "year" y "origin", además podemos observar que sólo las variables "displacemente", "horsepower" y "weight" hay mayor diferencia entre las poblaciones de la variable binaria "mpg1"

* Diagramas de cajas

```{r message=FALSE, warning=FALSE, , include=TRUE}
p1=Auto %>%
  ggplot(aes(mpg, cylinders, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "cylinders")

p2=Auto %>%
  ggplot(aes(mpg, displacement, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "displacement")

p3=Auto %>%
  ggplot(aes(mpg, horsepower, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "horsepower")

p4=Auto %>%
  ggplot(aes(mpg, weight, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "weight")

p5=Auto %>%
  ggplot(aes(mpg, acceleration, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "acceleration")

p6=Auto %>%
  ggplot(aes(mpg, year, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "year")

p7=Auto %>%
  ggplot(aes(mpg, origin, colour = mpg1)) +
  geom_boxplot() +
  labs(x = "mpg", y = "origin")

ggarrange(p1,p2,p3,p4,p5,p6,p7, nrow = 3, ncol = 3)

```

Lo observado en los diagramas de dispersión puede corroborarse en los diagramas de cajas, donde las medias más distantes entre poblaciones se encuentran en las variables "displacement", "horsepower" y "weight".

* Gráficos de densidad

```{r message=FALSE, warning=FALSE, , include=TRUE}
p1=Auto %>%
  ggplot(aes(cylinders, colour = mpg1)) +
  geom_density() 

p2=Auto %>%
  ggplot(aes(displacement, colour = mpg1)) +
  geom_density()

p3=Auto %>%
  ggplot(aes(horsepower, colour = mpg1)) +
  geom_density()

p4=Auto %>%
  ggplot(aes(weight, colour = mpg1)) +
  geom_density()

p5=Auto %>%
  ggplot(aes(acceleration, colour = mpg1)) +
  geom_density()

p6=Auto %>%
  ggplot(aes(year, colour = mpg1)) +
  geom_density()

p7=Auto %>%
  ggplot(aes(origin, colour = mpg1)) +
  geom_density()

ggarrange(p1,p2,p3,p4,p5,p6,p7, nrow = 3, ncol = 3)

```

Adicionalmente se ha visto necesario añadir gráficos de densidad para verificar los digramas de dispersión y cajas. Por tanto, eligiremos la variable "weight"  por tener mayor distancia entre las medias de la variable binaria "mpg1" y se descartan las variables "displacement" y "horsepower" por multicolinealidad. Adicionalmente probaremos en los modelos con las variables "cylinders","year" y "origin".

## c. Divida los datos en un conjunto de entrenamiento y un conjunto de prueba.

Se ha decidido dividir la data en 70% train y 30% test, realizando un muestreo estratificado por la variable de respuesta "mpg1" para asegurarnos la proporcionalidad del target en cada data creada.

```{r message=FALSE, warning=FALSE, , include=TRUE}
library(caret)
set.seed(604)
train.index <- createDataPartition(Auto$mpg1, p = .7, list = FALSE)
train <- Auto[ train.index,]
test  <- Auto[-train.index,]

prop.table(table(Auto$mpg1))
prop.table(table(train$mpg1))
prop.table(table(test$mpg1))
```

Como se observa la proporción del target en todas las datas (total, trains y test) es igual, lo cual asegura una estabilidad en el modelamiento. Por otro lado, para la data train quedaron 276 observaciones y para data test 116 observaciones:

```{r message=FALSE, warning=FALSE, , include=TRUE}
dim(train)[1]
dim(test)[1]
```

## d. Realice LDA en los datos de entrenamiento para predecir mpg01 usando las variables que parecían más asociada con mpg01 en (b). ¿Cuál es el error de prueba (test error) del modelo obtenido?

```{r , include=TRUE}
modelo_lda <- lda(mpg1 ~ cylinders+weight+year+origin, data = train)
modelo_lda
predicciones_train_lda <- predict(object = modelo_lda, train)
predicciones_test_lda <- predict(object = modelo_lda, test)
```

* Matriz de confusión en data test

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real =  test$mpg1,clase_predicha = predicciones_test_lda$class)
```

* Test de error de modelo LDA en el train y test respectivamente:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste("El % de error del modelo en train es:", mean(predicciones_train_lda$class != train$mpg1))
paste("El % de error del modelo en test es:", mean(predicciones_test_lda$class != test$mpg1))
```


## e. Realice QDA en los datos de entrenamiento para predecir mpg01 usando las variables que parecían más asociadas con mpg01 en (b). ¿Cuál es el error de prueba del modelo obtenido?

```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo_qda <- qda(mpg1 ~ cylinders + weight + year + origin, data = train)
modelo_qda
predicciones_train_qda <- predict(object = modelo_qda, train)
predicciones_test_qda <- predict(object = modelo_qda, test)
```

* Matriz de confusión en data test

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real =  test$mpg1,clase_predicha = predicciones_test_qda$class)
```

* Test de error de modelo QDA en el train y test respectivamente:

```{r message=FALSE, warning=FALSE, , include=TRUE}
paste("El % de error del modelo en train es:", mean(predicciones_train_qda$class != train$mpg1))
paste("El % de error del modelo en test es:", mean(predicciones_test_qda$class != test$mpg1))
```

Los resultados son mejores a los presentados con el modelo LDA.

## f. Realice una regresión logística en los datos de entrenamiento para predecir mpg01 usando las variables que parecían más asociadas con mpg01 en (b). ¿Cuál es el error de prueba del modelo obtenido?


```{r message=FALSE, warning=FALSE, , include=TRUE}
modelo <- glm(mpg1 ~ cylinders + weight + year + origin, data = train, family = "binomial")
summary(modelo)
predicciones.test <- predict(object = modelo, newdata = test, type = "response")
predicciones.test[predicciones.test > 0.5] <- 1
predicciones.test[predicciones.test <= 0.5] <- 0
predicciones.test <- as.factor(predicciones.test)

predicciones.train <- predict(object = modelo, newdata = train, type = "response")
predicciones.train[predicciones.train > 0.5] <- 1
predicciones.train[predicciones.train <= 0.5] <- 0
predicciones.train <- as.factor(predicciones.train)
```

* Matriz de confusión en data test

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_predicha = predicciones.test, clase_real = test$mpg1)
```

* Test de error de la regresión logística en el train y test respectivamente:

```{r message=FALSE, warning=FALSE, include=TRUE}
paste("El % de error del modelo en train es:", mean(predicciones.train != train$mpg1))
paste("El % de error del modelo en test es:", mean(predicciones.test != test$mpg1))
```

El test error en el modelo logístico es menor a los presentados en los modelos LDA y QDA.

## g. Realice KNN en los datos de entrenamiento, con varios valores de K, para predecir mpg01. Use solo las variables que parecían más asociadas con mpg01 en (b). ¿Qué errores de prueba obtienes? ¿Qué valor de K parece tener el mejor rendimiento en este conjunto de datos?

Antes de empezar con el modelamiento en Knn, estandarizacemos las variables "cylinders", "weight", "year" y "origin".

* **Modelo Knn con K=3**

```{r message=FALSE, warning=FALSE, include=TRUE}
#subsetting data set with desired variables
autoknn<-Auto[,c(2,5,7,8,10)]
#standardizing variables for knn
standardizedautoknn<-scale(autoknn[,-5])
#dividing in train and test data
train.index <- createDataPartition(Auto$mpg1, p = .7, list = FALSE)
autotrainknn = autoknn[train.index, ]
autotestknn = autoknn[-train.index, ]
library(class)
set.seed(123)
#KNN with k=3
knn.pred<-knn(autotrainknn[,-5],autotestknn[,-5],autotrainknn[,as.factor(mpg1)],k=3)
knn.pred.train<-knn(autotrainknn[,-5],autotrainknn[,-5],autotrainknn[,as.factor(mpg1)],k=3)
```

* Matriz de confusión de modelo KNN con K = 3

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = autotestknn$mpg1,clase_predicha = knn.pred)
```
* Test de error de modelo KNN con K = 3 en el train y test respectivamente:

```{r message=FALSE, warning=FALSE, include=TRUE}
paste("El % de error del modelo en train es:", mean(knn.pred.train != autotrainknn$mpg1))
paste("El % de error del modelo en test es:", mean(knn.pred != autotestknn$mpg1))
```

El test de error del modelo KNN con K = 3 es mucho mayor al de los modelos desarrollados antes.

* **Modelo Knn con K=6**

```{r message=FALSE, warning=FALSE, include=TRUE}
set.seed(123)
#KNN with k=50
knn.pred<-knn(autotrainknn[,-5],autotestknn[,-5],autotrainknn[,as.factor(mpg1)],k=6)
knn.pred.train<-knn(autotrainknn[,-5],autotrainknn[,-5],autotrainknn[,as.factor(mpg1)],k=6)
```

* Matriz de confusión de modelo KNN con K = 6

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = autotestknn$mpg1,clase_predicha = knn.pred)
```
* Test de error de modelo KNN con K = 6 en el train y test respectivamente:

```{r message=FALSE, warning=FALSE, include=TRUE}
paste("El % de error del modelo en train es:", mean(knn.pred.train != autotrainknn$mpg1))
paste("El % de error del modelo en test es:", mean(knn.pred != autotestknn$mpg1))
```

El test de error del modelo KNN con K = 6, es mejor al obtenido con K = 3, pero igual es mayor a los modelos presentados anteriormente.

---

# 3. Utilizando el conjunto de datos de Boston del paquete MASS, ajuste los modelos de clasificación para predecir la tasa de delincuencia en los suburbios de Boston que esté por encima o por debajo de la mediana. Explore los modelos de regresión logística, LDA y KNN usando varios subconjuntos de predictores. Describe sus hallazgos.

---

Al igual que en el problema 2, comenzamos importando los datos y creando la variable binaria que será nuestra variable respuesta a predecir.

```{r message=FALSE, warning=FALSE, , include=TRUE}
Boston <- data.table(Boston)
mediana.crime <- median(Boston$crim)
Boston[ , indice := as.factor(ifelse(crim > mediana.crime, 1, 0))]
Boston[sample(1:nrow(Boston), 15),]
```

En este problema también se ha decidido dividir la data en 70% train y 30% test, realizando un muestreo estratificado por la variable de respuesta "indice", que proviene de la variable "crim", para asegurarnos la proporcionalidad del target en cada data creada.

```{r message=FALSE, warning=FALSE, , include=TRUE}
library(caret)
set.seed(604)
train.index <- createDataPartition(Boston$indice, p = .7, list = FALSE)
train <- Boston[ train.index,]
test  <- Boston[-train.index,]

prop.table(table(Boston$indice))
prop.table(table(Boston$indice))
prop.table(table(Boston$indice))
```

Como se observa la proporción del target en todas las datas (total, trains y test) es igual, lo cual asegura una estabilidad en el modelamiento. Por otro lado, para la data train quedaron 356 observaciones y para data test 150 observaciones:

```{r message=FALSE, warning=FALSE, , include=TRUE}
dim(train)[1]
dim(test)[1]
```

* **Modelo logístico**

Creamos un modelo tradicional y otro haciendo stepwise minimizando el AIC del modelo.

```{r message=FALSE, warning=FALSE, include=TRUE}
fit.logit <- glm(indice ~ zn + indus + chas + nox + rm +age + dis + rad + tax + ptratio + black +lstat + medv, data = train, family = "binomial")
fit.logit.2 <- stepAIC(fit.logit, trace = FALSE)
summary(fit.logit.2)
modelo<- glm(indice ~ zn + nox+ rad + tax + ptratio + black + medv, data = train,family = "binomial")
summary(modelo)
```

Matriz de confusión del modelo logístico:
```{r message=FALSE, warning=FALSE,include=TRUE}
predicciones2 <- predict(object = modelo, newdata = test, type = "response")

# Se considera como threshold de clasificación el 0.5
predicciones2[predicciones2 > 0.5] <- 1
predicciones2[predicciones2 <= 0.5] <- 0
predicciones2 <- as.factor(predicciones2)

table(clase_real = test$indice,clase_predicha = predicciones2)
```

Indicadores de Accuracy y error:

```{r message=FALSE, warning=FALSE,include=TRUE}
# % de aciertos
paste("% de acierto:", mean(predicciones2 == test$indice))

# % de errores
paste("% de error:", mean(predicciones2 != test$indice))
```

* **Modelo LDA**

```{r message=FALSE, warning=FALSE, , include=TRUE}
#lda
modelo_lda <- lda(indice ~ zn + nox + dis + rad + tax + ptratio + black + medv, data = train)
modelo_lda
```

Matriz de confusión del modelo LDA:

```{r message=FALSE, warning=FALSE, , include=TRUE}
predicciones_lda <- predict(object = modelo_lda, test)
table(clase_real =  test$indice,clase_predicha = predicciones_lda$class)
```

Indicadores de Accuracy y error:

```{r message=FALSE, warning=FALSE,include=TRUE}
# % de aciertos
paste("% de acierto:", mean(predicciones_lda$class == test$indice))

# % de errores
paste("% de error:", mean(predicciones_lda$class != test$indice))
```

* **Modelo Knn, con K = 1**

```{r message=FALSE, warning=FALSE, , include=TRUE}
#KNN k=1
set.seed(604)
prediccion_knn2 <- knn(train = train[,c("zn","nox","dis","rad","tax","ptratio","black","medv")],
                       test = test[,c("zn","nox","dis","rad","tax","ptratio","black","medv")] ,
                       cl = train[["indice"]], k = 1)
```

Matriz de confusión del modelo Knn con K=1:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = test$indice,clase_predicha = prediccion_knn2)
```

Indicadores de Accuracy y error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de aciertos
paste("% de acierto:", mean(prediccion_knn2 == test$indice))
# % de errores
paste("% de error:", mean(prediccion_knn2 != test$indice))

```

* **Modelo Knn, con K = 3**

```{r message=FALSE, warning=FALSE, , include=TRUE}
set.seed(604)
prediccion_knn3 <- knn(train = train[,c("zn","nox","dis","rad","tax","ptratio","black","medv")],
                       test = test[,c("zn","nox","dis","rad","tax","ptratio","black","medv")] ,
                       cl = train[["indice"]], k = 3)
```

Matriz de confusión del modelo Knn con K = 3:

```{r message=FALSE, warning=FALSE, , include=TRUE}
table(clase_real = test$indice,clase_predicha = prediccion_knn3)
```

Indicadores de Accuracy y error:

```{r message=FALSE, warning=FALSE, , include=TRUE}
# % de aciertos
paste("% de acierto:", mean(prediccion_knn3 == test$indice))
# % de errores
paste("% de error:", mean(prediccion_knn3 != test$indice))
```

Finalmente el modelo con mayor porcentaje de aciertos y por ende menor error de clasificación es el KNN con K = 1.
---
title: 'PC1 - Minería de Datos'
author: "Anilda Guevara"
date: '`r Sys.Date()`'
output: html_document

---
<style>
body {
text-align: justify}
</style>
---

```{r setup, include=FALSE}
pacman::p_load(pacman,tidyr,dplyr,ggplot2,knitr,rmarkdown,data.table,truncnorm,MCMCpack,mice,data.table,
               scatterplot3d,GGally, ggplot2,naniar,UpSetR,tidyr,MLmetrics,Metrics,imputeR,VIM,cowplot,pdp,
               UsingR,MASS,missForest,naniar)
options(scipen = 999)
setwd("D:/Estadistica/maestría/Ciclo III/Mineria de datos/PC1")
knitr::opts_chunk$set(echo = TRUE)
```

---

#1. Cual es el supuesto de aleatoriedad con el trabaja el paquete mice. 

---

La imputación multivariada mediante ecuaciones encadenadas (MICE) es una técnica particular de imputación múltiple. MICE opera por default bajo el supuesto: dadas las variables utilizadas en el procedimiento de imputación, los datos son missing at random (MAR), lo que significa que la probabilidad de que falte un valor depende solo de los valores observados y no de los valores no observados. En otras palabras, después de controlar todos los datos disponibles  "cualquier missing value es completamente aleatorio". MICE también puede manejar el supuesto missing not at random (MNAR) que requiere supuestos de modelado adicionales que influyen en las imputaciones generadas.

En el procedimiento MICE se ejecutan una serie de modelos de regresión en los que cada variable con datos faltantes se modela condicionalmente a las otras variables. Esto significa que cada variable se puede modelar de acuerdo con su distribución, por ejemplo, las variables binarias pueden ser modeladas usando regresión logística y las variables continuas modeladas usando regresión lineal.

---

#2. Utilizando el conjunto de datos, iris2.csv, haga un breve análisis descriptivo (incluya tablas, gráficos) y las interpretaciones que crea conveniente. Utilice un paquete o paquetes de R para realizar las imputaciones al conjunto de datos y haga comparaciones (considere por ejemplo RMSE normalizado) 

---

#Carga de la base de datos y descripción de las variables

El conjunto de datos iris está compuesto de 150 filas y 5 variables, de las cuales 4 son numéricas y 1 es de tipo character (Species)

```{r, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
data_iris <- fread('iris2.csv')
str(data_iris); dim(data_iris)
```

A continuación se realiza un pequeña descripción de cada variable que procederemos a analizar en las siguientes secciones:
* Sepal.Length: Largo del sépalo en cm
* Sepal.Width Ancho del sépalo en cm
* Petal.Lengt: Largo del pétalo en cm
* Petal.Width: Ancho del pétalo en cm
* Species: Especie de iris
* Color: Color de la flor

Así también podemos observar que de las 5 variables que contiene la base de datos 3 tienen valores perdidos o missing:

```{r, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
summary(data_iris[,c(2:6)])
# table(data_iris$Species,useNA = "ifany")
```


#Análisis descriptivo

Antes de inciar con la imputación de las 3 variables que contienen valores perdidos, analizaremos de las medias de las variables por el tipo de especie: Setosa, Versicolor y Virginica. 

En el siguiente cuadro podemos apreciar, que las medias (sin considerar valores perdidos), que tienen mayor distancia entre especies son las relacionadas a "Petal" (Petal.Width y Petal.Length). Cuando realicemos la imputaciónde los datos, se espera que las medias y éste análisis no sea similar.

```{r, message=FALSE, warning=FALSE, include=TRUE}
medias_sin_imputar= data_iris[ , .(media.Sepal.Length=mean(na.omit(Sepal.Length)),
                                   media.Sepal.Width=mean(na.omit(Sepal.Width)),
                                   media.Petal.Length=mean(na.omit(Petal.Length)),
                                   media.Petal.Width=mean(na.omit(Petal.Width))), by=(Species)]
medias_sin_imputar
```

Lo mencionado en el parráfo anterior, también lo podemos observar mediante un gráficos de dispersión,boxplot y densidades:

```{r, message=FALSE, warning=FALSE, include=TRUE}
p=ggpairs(data_iris[,c(-1)], aes(color= Species))+ theme_bw()

for(i in 1:p$nrow) {
  for(j in 1:p$ncol){
    p[i,j] = p[i,j]+
      scale_fill_manual(values=c("#00AFBB", "#E7B800", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#E7B800", "#FC4E07"))
    }
};p
```

#Análisis de valores perdidos

Procedemos a realizar una visualización de la cantidad de valores perdidos en cada variable:
 
```{r, message=FALSE, warning=FALSE, include=TRUE}
vis_miss(data_iris[,2:5])
```

* Sepal Length tiene completos sus datos
* Sepal Width tiene el 13.33% de los datos con NA
* Petal Length tiene el 20% de los datos con NA
* Petal Width tiene el 10% de los datos con NA

En general el 10.8% de la data tiene valores perdidos.

```{r, message=FALSE, warning=FALSE, include=TRUE}
gg_miss_upset(data_iris[,2:5])
```

En este gráfico podemos observar que existen en total hay 65 registros con valores perdidos, y además las relaciones entre las variables, es decir, cuando un mismo registro presenta el valor perdido en más de 1 varible. Por ejemplo, existen 2 registros que tienen valor perdido en Petal Width y Sepal Width simultáneamente.

```{r, message=FALSE, warning=FALSE, include=TRUE}
gg_miss_var(data_iris[,2:6],
            show_pct = TRUE ,
            facet = Species)
```

En este gráfico se observan el número de registros con valores perdidos por variale y Specie, observándose que para Specie Setosa la variable con mayor volumen de valores perdidos es Sepal Width mientras que para las Species Vesicolor y Virginia es la variable Petal Length.

##Imputaciones

A continuación se realizan las impuestaciones con los paquetes MICE y VIM. En el caso de MICE se utiliza se utiliza la media y luego el algortitmo "predictive mean matching"; posteriormente se realizar las comparaciones.

**Imputaciones con el algoritmo "Pmm" con el paquete Mice**

En la función "mice" colocamos el método de imputación "pmm" debido a que se realiazan imputaciones sobre variables numéricas:

```{r, message=FALSE, warning=FALSE, include=TRUE}
imputed.mice.pmm= mice(data_iris[,2:6],
              m=5,
              maxit = 50,
              meth= 'pmm',
              seed=23109, print=FALSE)
imputed.data.mice.pmm=complete(imputed.mice.pmm,1)
```

Verificamos si efectivamente ya no existen valores vacíos en la data iris

```{r, message=FALSE, warning=FALSE, include=TRUE}
sapply(imputed.data.mice.pmm, function(x) sum(is.na(x)))
```

Se realiza nuevamente las correlaciones y las medias de las variables según "Species" considerando los valores imputados por el algoritmo pmm del paquete "Mice"

```{r, message=FALSE, warning=FALSE, include=TRUE}
## Variables con Specie
p2=ggpairs(imputed.data.mice.pmm, aes(color= Species))+ theme_bw()

for(i in 1:p2$nrow) {
  for(j in 1:p2$ncol){
    p2[i,j] = p2[i,j]+
      scale_fill_manual(values=c("#00AFBB", "#E7B800", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#E7B800", "#FC4E07"))
  }
}
p2
```

Si comparamos con las medias imputadas con el algoritmo "pmm" del paquete "Mice" con las medias de las variables por especie que no contenian los valores perdidos, podemos observar que las diferencias son mínimas. Sin embargo, procederemos a realizar imputación con la media y otro paquete para medir su eficiencia y compararlo con otros algoritmos.

```{r, message=FALSE, warning=FALSE, include=TRUE}
imputed.data.mice.pmm=data.table(imputed.data.mice.pmm)
medias_sin_imputar
imputed.data.mice.pmm[ , .(media.Sepal.Length=mean(na.omit(Sepal.Length)),
               media.Sepal.Width=mean(na.omit(Sepal.Width)),
               media.Petal.Length=mean(na.omit(Petal.Length)),
               media.Petal.Width=mean(na.omit(Petal.Width))), by=(Species)]
```

**Imputaciones con la media con el paquete Mice**

Modificamos en la función "mice" el método a "mean":

```{r, message=FALSE, warning=FALSE, include=TRUE}
imputed.mice.mean= mice(data_iris[,2:6],
               m=5,
               maxit = 50,
               meth= 'mean',
               seed=23109, print=FALSE)
imputed.data.mice.mean=complete(imputed.mice.mean,1)
```

Verificamos si efectivamente ya no existen valores vacíos en la data iris:

```{r, message=FALSE, warning=FALSE, include=TRUE}
sapply(imputed.data.mice.mean, function(x) sum(is.na(x)))
```

Se realiza nuevamente las correlaciones y las medias de las variables según "Species" considerando los valores imputados com la media del paquete "Mice"

```{r, message=FALSE, warning=FALSE, include=TRUE}
p2=ggpairs(imputed.data.mice.mean, aes(color= Species))+ theme_bw()
for(i in 1:p2$nrow) {
  for(j in 1:p2$ncol){
    p2[i,j] = p2[i,j]+
      scale_fill_manual(values=c("#00AFBB", "#E7B800", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#E7B800", "#FC4E07"))
  }
}

p2
```

Si comparamos con las medias imputadas con la media del paquete "Mice" con las medias de las variables por especie que no contenian los valores perdidos, podemos observar que las medias con éste método son más distantes comparadas con las medias de los datos antes de imputar. Sin embargo,lo mencionado se verificará con el cálculo  y comparación del RMSE de los métodos de imputación utilizados.

```{r, message=FALSE, warning=FALSE, include=TRUE}
imputed.data.mice.mean=data.table(imputed.data.mice.mean)
medias_sin_imputar
imputed.data.mice.mean[ , .(media.Sepal.Length=mean(na.omit(Sepal.Length)),
               media.Sepal.Width=mean(na.omit(Sepal.Width)),
               media.Petal.Length=mean(na.omit(Petal.Length)),
               media.Petal.Width=mean(na.omit(Petal.Width))), by=(Species)]
```

**Imputaciones con el paquete VIM**

```{r, message=FALSE, warning=FALSE, include=TRUE}
str(data_iris[,c(2:6)])
data=as.data.frame(data_iris[,c(2:6)])
data$Species=as.factor(data$Species)
set.seed(23109)
imputed.irmi= irmi(data)
imputedData.irmi=imputed.irmi[,c(1:5)]
```

Verificamos si efectivamente ya no existen valores vacíos en la data iris

```{r, message=FALSE, warning=FALSE, include=TRUE}
sapply(imputedData.irmi, function(x) sum(is.na(x)))
```

Se realizan nuevamente loa gráficos de correlación y dispersión de los data que contiene la imputación realizada del paquete "VIM"

```{r, message=FALSE, warning=FALSE, include=TRUE}
p3=ggpairs(imputedData.irmi, aes(color= Species))+ theme_bw()

for(i in 1:p2$nrow) {
  for(j in 1:p2$ncol){
    p2[i,j] = p2[i,j]+
      scale_fill_manual(values=c("#00AFBB", "#E7B800", "#FC4E07")) +
      scale_color_manual(values=c("#00AFBB", "#E7B800", "#FC4E07"))
  }
};p3
```

Si comparamos con las medias imputadas con el paquete "VIM" con las medias de las variables por especie que no contenian los valores perdidos, podemos observar que las medias con éste método son muy parecudas a las medias de los datos antes de imputar y a las obtenidas con el algoritmo "pmm". Ahora si procederemos a comparar numéricamente los métodos de imputación aplicados.

```{r, message=FALSE, warning=FALSE, include=TRUE}
imputedData.irmi=data.table(imputedData.irmi)
medias_sin_imputar
imputedData.irmi[ , .(media.Sepal.Length=mean(na.omit(Sepal.Length)),
               media.Sepal.Width=mean(na.omit(Sepal.Width)),
               media.Petal.Length=mean(na.omit(Petal.Length)),
               media.Petal.Width=mean(na.omit(Petal.Width))), by=(Species)]
```


Para evaluar el mejor método de imputación calculamos la raíz del error cuadrático medio  (RSME) entre dos vectores numéricos; mice con pmm e irmi (del paquete VIM) presentan los mejores resultados de RMSE frente a la imputación con la media que data un RMSE de 0.75.

```{r, message=FALSE, warning=FALSE, include=TRUE}
## data True
data(iris)

### RMSE - pmm
RMSE.pmm=Rmse(imputed.data.mice.pmm[,1:4],as.data.frame(data_iris)[,2:5], iris[,1:4], norm = TRUE)

### RMSE - media
RMSE.media=Rmse(imputed.data.mice.mean[,1:4],as.data.frame(data_iris)[,2:5], iris[,1:4], norm = TRUE)

### RMSE - irmi
RMSE.irmi=Rmse(imputedData.irmi[,1:4],as.data.frame(data_iris)[,2:5], iris[,1:4], norm = TRUE)

cbind(RMSE.pmm,RMSE.media,RMSE.irmi)
```

**Gráficos de densidad de los métodos de imputación utilizados**

Se han realizado gráficos de densidad de las variables imputadas según especie y se obsevará las diferencias obtenidas por cada método de imputación aplicado:

```{r, message=FALSE, warning=FALSE, include=TRUE}
### Separamos las datas por Especie
iris=data.table(iris)
iris.setosa=iris[Species=="setosa",]
imputed.data.mice.mean.setosa=imputed.data.mice.mean[Species=="setosa",]
imputed.data.mice.pmm.setosa=imputed.data.mice.pmm[Species=="setosa",]
imputed.data.irmi.setosa=imputedData.irmi[Species=="setosa",]

iris.virginica=iris[Species=="virginica",]
imputed.data.mice.mean.virginica=imputed.data.mice.mean[Species=="virginica",]
imputed.data.mice.pmm.virginica=imputed.data.mice.pmm[Species=="virginica",]
imputed.data.irmi.virginica=imputedData.irmi[Species=="virginica",]

iris.versicolor=iris[Species=="versicolor",]
imputed.data.mice.mean.versicolor=imputed.data.mice.mean[Species=="versicolor",]
imputed.data.mice.pmm.versicolor=imputed.data.mice.pmm[Species=="versicolor",]
imputed.data.irmi.versicolor=imputedData.irmi[Species=="versicolor",]

```

* Especie - Setosa:

```{r, message=FALSE, warning=FALSE, include=TRUE}
### Graficamos las densidades por especie y método de imputación aplicado
par(mfrow=c(1,3))

## Setosa - Sepal.Width

plot(density(iris.setosa$Sepal.Width),col="blue",xlim=c(1.7,5),ylim=c(0,1.8),main="Setosa - Sepal.Width")
lines(density(imputed.data.mice.mean.setosa$Sepal.Width),col="red")
lines(density(imputed.data.mice.pmm.setosa$Sepal.Width),col="brown")
lines(density(imputed.data.irmi.setosa$Sepal.Width),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))

## Setosa - Petal.Length

plot(density(iris.setosa$Petal.Length),col="blue",xlim=c(0.7,4),ylim=c(0,3.0),main="Setosa - Petal.length")
lines(density(imputed.data.mice.mean.setosa$Petal.Length),col="red")
lines(density(imputed.data.mice.pmm.setosa$Petal.Length),col="brown")
lines(density(imputed.data.irmi.setosa$Petal.Length),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))


## Setosa - Petal.Width

plot(density(iris.setosa$Petal.Width),col="blue",xlim=c(0,1.5),ylim=c(0,8.0),main="Setosa - Petal.Width")
lines(density(imputed.data.mice.mean.setosa$Petal.Width),col="red")
lines(density(imputed.data.mice.pmm.setosa$Petal.Width),col="brown")
lines(density(imputed.data.irmi.setosa$Petal.Width),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))

```

* Especie Virginica

```{r, message=FALSE, warning=FALSE, include=TRUE}
## Virginica - Sepal.Width
par(mfrow=c(1,3))

plot(density(iris.virginica$Sepal.Width),col="blue",xlim=c(1.5,4.3),ylim=c(0,2.3),main="Virginica - Sepal.Width")
lines(density(imputed.data.mice.mean.virginica$Sepal.Width),col="red")
lines(density(imputed.data.mice.pmm.virginica$Sepal.Width),col="brown")
lines(density(imputed.data.irmi.virginica$Sepal.Width),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))

## Virginica - Petal.Length

plot(density(iris.virginica$Petal.Length),col="blue",xlim=c(2,8.3),ylim=c(0,0.9),main="Virginica - Petal.Length")
lines(density(imputed.data.mice.mean.virginica$Petal.Length),col="red")
lines(density(imputed.data.mice.pmm.virginica$Petal.Length),col="brown")
lines(density(imputed.data.irmi.virginica$Petal.Length),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))


## Virginica - Petal.Width

plot(density(iris.virginica$Petal.Width),col="blue",xlim=c(0.5,3.2),ylim=c(0,1.75),main="Virginica - Petal.Width")
lines(density(imputed.data.mice.mean.virginica$Petal.Width),col="red")
lines(density(imputed.data.mice.pmm.virginica$Petal.Width),col="brown")
lines(density(imputed.data.irmi.virginica$Petal.Width),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))
```

* Especie Versicolor
```{r, message=FALSE, warning=FALSE, include=TRUE}
## Versicolor - Sepal.Width 
par(mfrow=c(1,3))

plot(density(iris.versicolor$Sepal.Width),col="blue",xlim=c(1.3,4),ylim=c(0,1.7),main="Versicolor - Sepal.Width")
lines(density(imputed.data.mice.mean.versicolor$Sepal.Width),col="red")
lines(density(imputed.data.mice.pmm.versicolor$Sepal.Width),col="brown")
lines(density(imputed.data.irmi.versicolor$Sepal.Width),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))


## Versicolor - Petal.Length

plot(density(iris.versicolor$Petal.Length),col="blue",xlim=c(2,6),ylim=c(0,1.2),main="Versicolor - Petal.Length")
lines(density(imputed.data.mice.mean.versicolor$Petal.Length),col="red")
lines(density(imputed.data.mice.pmm.versicolor$Petal.Length),col="brown")
lines(density(imputed.data.irmi.versicolor$Petal.Length),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))


## Versicolor - Petal.Width

plot(density(iris.versicolor$Petal.Width),col="blue",xlim=c(0.6,2.2),ylim=c(0,2.4),main="Versicolor - Petal.Width")
lines(density(imputed.data.mice.mean.versicolor$Petal.Width),col="red")
lines(density(imputed.data.mice.pmm.versicolor$Petal.Width),col="brown")
lines(density(imputed.data.irmi.versicolor$Petal.Width),col="green")
legend("topright", c("Iris","Mice mean","Mice.pmm","Irmi"), lty = c(1,1,1,1), col = c("blue","red","brown","green"))

```

Gráficamente también podemos concluir que los métodos "pmm" e "irmi" se ajustan mejor a los datos reales según especie.

---

#3. Elija un conjunto de datos e incorpore en forma aleatoria datos perdidos y luego busque imputarlos. Así como en la pregunta anterior, realice un breve análisis descriptivo y haga comparaciones de las técnicas de imputaciones escogidas (elija el criterio de comparación).

---

##Carga de datos y descripción de las variables

De acuerdo con los criterios de la Organización Mundial de la Salud, se realizó una prueba de detección de diabetes en una población de mujeres que tenían al menos 21 años, de origen indígena pima y que vivían cerca de Phoenix, Arizona. Los datos fueron recopilados por el Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales de los Estados Unidos. 

```{r, message=FALSE, warning=FALSE, include=TRUE}
library(MASS)
data("Pima.tr")
head(Pima.tr)
```

Las variables que contiene la data son:

* npreg : número de embarazos
* glu: Concentración plasmática de glucosa en una prueba oral de tolerancia a la glucosa.
* bp: Presión arterial diastólica (mm Hg).
* skin: Tríceps piel pliegue espesor (mm).
* bmi: índice de masa corporal (peso en kg / (altura en m) \ ^ 2).
* ped: diabetes pedigrí función
* age: edad en años
* type: Sí o No, para diabéticos según criterios de la OMS.

La data contiene 200 observaciones con 8 variables, siendo la variable type la de respuesta binaria, el resto son variables numéricas

```{r, message=FALSE, warning=FALSE, include=TRUE}
dim(Pima.tr)
str(Pima.tr)
```

Verificamos que la data original no contiene valores perdidos:

```{r, message=FALSE, warning=FALSE, include=TRUE}
vis_miss(Pima.tr)
```

Observamos que la data no contiene NA, ahora guardaremos la data original para realizar unos pequeños desciptivos y luego comparar la efectividad de las imputaciones realizadas:

```{r, message=FALSE, warning=FALSE, include=TRUE}
## Guardamos la data original
original= Pima.tr
```

##Análisis descriptivo de la data Original

Realizamos unos gráficos de densidad de las variables numérica según la variable de respuesta binaria (Tiene/No tiene diabetes). Los aleatorios que creemos y las imputaciones debería recuperarnos las densidades observadas:

```{r, message=FALSE, warning=FALSE, include=TRUE}
p1.npreg=original %>%
          ggplot(aes(npreg, fill = type)) +
          geom_density(position = "stack",alpha=0.5)

p2.glu=original %>%
  ggplot(aes(glu, fill = type)) +
  geom_density(position = "stack",alpha=0.5)

p3.bp=original %>%
  ggplot(aes(bp, fill = type)) +
  geom_density(position = "stack",alpha=0.5)

p4.skin=original %>%
  ggplot(aes(skin, fill = type)) +
  geom_density(position = "stack",alpha=0.5)

p5.bmi=original %>%
  ggplot(aes(bmi, fill = type)) +
  geom_density(position = "stack",alpha=0.5)

p6.ped=original %>%
  ggplot(aes(ped, fill = type)) +
  geom_density(position = "stack",alpha=0.5)

p7.age=original %>%
  ggplot(aes(age, fill = type)) +
  geom_density(position = "stack",alpha=0.5)

grid.arrange(p1.npreg,p2.glu,p3.bp,p4.skin,p5.bmi,p6.ped,p7.age, nrow=4)

```

##Creación de "missing" aleatorios al data set

Creamos 10% de valores aleatorios a los registros de la base a cada una de las variables, incluyendo la variable de respuesta binaria, de la siguiente forma:

```{r, message=FALSE, warning=FALSE, include=TRUE}
set.seed(123)
missData=data.table(SimIm(Pima.tr,0.1))
names(missData)= c("npreg","glu","bp","skin","bmi","ped","age","type")
missData
```

Verificamos el número de missing creados por variable

```{r, message=FALSE, warning=FALSE, include=TRUE}
sapply(missData, function(x) sum(is.na(x)))
```

##Imputación de los valores perdidos aleatorios creados

A continuación se compara 2 algoritmos (en las variables numéricas) que contiene el paquete "Mice": "Pmm" y "rf" (Random Forest). Adicionalmente, utilizamos el método "mean". Para la variable de respuesta binaria se utilizó "logreg.boot" (Regresión logística con bootstrap)

**Mice con algoritmo Pmm**

```{r, message=FALSE, warning=FALSE, include=TRUE}
missData[, type:=as.factor(type)]
# Mice - pmm
init = mice(missData , maxit=10)
meth = init$method
predM = init$predictorMatrix

meth[c("npreg")]="pmm"
meth[c("glu")]="pmm"
meth[c("bp")]="pmm"
meth[c("skin")]="pmm"
meth[c("bmi")]="pmm"
meth[c("ped")]="pmm"
meth[c("age")]="pmm"
meth[c("type")]="logreg.boot"

set.seed(123)
imputed.mice.pmm = mice(missData, method=meth , predictorMatrix=predM , m=5,seed = 123,diag=FALSE, print=FALSE)
imputed.data.mice.pmm= complete(imputed.mice.pmm)

```

**Mice con algoritmo Random Forest**

```{r, message=FALSE, warning=FALSE, include=TRUE}
init = mice(missData , maxit=10)
meth = init$method
predM = init$predictorMatrix

meth[c("npreg")]="rf"
meth[c("glu")]="rf"
meth[c("bp")]="rf"
meth[c("skin")]="rf"
meth[c("bmi")]="rf"
meth[c("ped")]="rf"
meth[c("age")]="rf"
meth[c("type")]="logreg.boot"

set.seed(123)
imputed.mice.rf = mice(missData, method=meth , predictorMatrix=predM , m=5,seed = 123,diag=FALSE, print=FALSE)
imputed.data.mice.rf = complete(imputed.mice.rf)

```

**Mice con Mean**

```{r, message=FALSE, warning=FALSE, include=TRUE}
init = mice(missData , maxit=10)
meth = init$method
predM = init$predictorMatrix

meth[c("npreg")]="mean"
meth[c("glu")]="mean"
meth[c("bp")]="mean"
meth[c("skin")]="mean"
meth[c("bmi")]="mean"
meth[c("ped")]="mean"
meth[c("age")]="mean"
meth[c("type")]="logreg.boot"

set.seed(123)
imputed.mice.mean = mice(missData, method=meth , predictorMatrix=predM , m=5,seed = 123,diag=FALSE, print=FALSE)
imputed.data.mice.mean= complete(imputed.mice.mean)

```

## Vericación de las medias de las variables numéricas imputadas


```{r, message=FALSE, warning=FALSE, include=TRUE}
medias.original=original %>%
  group_by(type) %>%
  summarise(mean.npreg=mean(npreg),
            mean.glu=mean(glu),
            mean.bp=mean(bp),
            mean.skin=mean(skin),
            mean.bmi=mean(bmi),
            mean.ped=mean(ped),
            mean.age=mean(age))

medias.mice.rf=imputed.data.mice.rf %>%
  group_by(type) %>%
  summarise(mean.npreg=mean(npreg),
            mean.glu=mean(glu),
            mean.bp=mean(bp),
            mean.skin=mean(skin),
            mean.bmi=mean(bmi),
            mean.ped=mean(ped),
            mean.age=mean(age))

medias.mice.pmm=imputed.data.mice.pmm %>%
  group_by(type) %>%
  summarise(mean.npreg=mean(npreg),
            mean.glu=mean(glu),
            mean.bp=mean(bp),
            mean.skin=mean(skin),
            mean.bmi=mean(bmi),
            mean.ped=mean(ped),
            mean.age=mean(age))

medias.mice.mean=imputed.data.mice.mean %>%
  group_by(type) %>%
  summarise(mean.npreg=mean(npreg),
            mean.glu=mean(glu),
            mean.bp=mean(bp),
            mean.skin=mean(skin),
            mean.bmi=mean(bmi),
            mean.ped=mean(ped),
            mean.age=mean(age))

list(medias.original=data.frame(medias.original),
     medias.mice.rf=data.frame(medias.mice.rf),
     medias.mice.pmm=data.frame(medias.mice.pmm),
     medias.mice.mean=data.frame(medias.mice.mean))

```
En el cuadro de comparación de medias, se observa que los algoritmos utilizados "pmm" y "mean" recuperan de con menor distancia la media original (antes de la creación de los valores missing). Sin embargo, el método de la "rf" (Random Forest), tiene mayores distancias. Comprobaremos ésto por medio del RMSE normalizado:

```{r, message=FALSE, warning=FALSE, include=TRUE}
#### RMSE normalizado

Rmse.mice.rf=Rmse(imputed.data.mice.rf[,1:7],as.data.frame(missData)[,1:7], original[,1:7], norm = TRUE)

Rmse.mice.pmm=Rmse(imputed.data.mice.pmm[,1:7],as.data.frame(missData)[,1:7], original[,1:7], norm = TRUE)

Rmse.mice.mean=Rmse(imputed.data.mice.mean[,1:7],as.data.frame(missData)[,1:7], original[,1:7], norm = TRUE)

Rmse.com=data.table(Rmse.mice.rf=Rmse.mice.rf, Rmse.mice.pmm=Rmse.mice.pmm, Rmse.mice.mean=Rmse.mice.mean)
Rmse.com

```

Con éste indicador, podemos comprobar lo indicado en el párrafo anterior. A pesar que el algotirmo "rf" es más robusto que el método "mean"; sin embargo, observaremos visualmente qué tanto impacto tienen según variable de respuesta.

**Gráficos de densidad de los métodos de imputación utilizados**

Se han realizado gráficos de densidad de las variables imputadas según la variable de respuesta binaria y se obsevará las diferencias obtenidas por cada método de imputación aplicado:

* Type=Yes

```{r, message=FALSE, warning=FALSE, include=TRUE}
### Graficamente por la Clase "Yes"/"No"

original=data.table(original)
imputed.data.mice.rf=data.table(imputed.data.mice.rf)
imputed.data.mice.pmm=data.table(imputed.data.mice.pmm)
imputed.data.mice.mean=data.table(imputed.data.mice.mean)

### Graficamos las densidades por especie y método de imputación aplicado
par(mfrow=c(2,2))

## YES - npreg
plot(density(original[type=="Yes",]$npreg),col="blue",xlim=c(0,15.0),ylim=c(0,0.1),main="YES - npreg")
lines(density(imputed.data.mice.rf[type=="2",]$npreg),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$npreg),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$npreg),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"), 
       lty =c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

## YES - glu
plot(density(original[type=="Yes",]$glu),col="blue",xlim=c(44,234),ylim=c(0,0.02),main="YES - glu")
lines(density(imputed.data.mice.rf[type=="2",]$glu),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$glu),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$glu),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"), 
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

## YES - bp
plot(density(original[type=="Yes",]$bp),col="blue",xlim=c(26,119),ylim=c(0,0.04),main="YES - bp")
lines(density(imputed.data.mice.rf[type=="2",]$bp),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$bp),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$bp),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"), 
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)


## YES - skin
plot(density(original[type=="Yes",]$skin),col="blue",xlim=c(0,111),ylim=c(0,0.05),main="YES - skin")
lines(density(imputed.data.mice.rf[type=="2",]$skin),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$skin),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$skin),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"), 
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

par(mfrow=c(2,2))

## YES - bmi
plot(density(original[type=="Yes",]$bmi),col="blue",xlim=c(17,52),ylim=c(0,0.1),main="YES - bmi")
lines(density(imputed.data.mice.rf[type=="2",]$bmi),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$bmi),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$bmi),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)


## YES - ped
plot(density(original[type=="Yes",]$ped),col="blue",xlim=c(0,2.8),ylim=c(0,1.65),main="YES - ped")
lines(density(imputed.data.mice.rf[type=="2",]$ped),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$ped),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$ped),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)


## YES - age
plot(density(original[type=="Yes",]$age),col="blue",xlim=c(7,76),ylim=c(0,0.035),main="YES - age")
lines(density(imputed.data.mice.rf[type=="2",]$age),col="red")
lines(density(imputed.data.mice.pmm[type=="2",]$age),col="brown")
lines(density(imputed.data.mice.mean[type=="2",]$age),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

```


* Type=No

```{r, message=FALSE, warning=FALSE, include=TRUE}
par(mfrow=c(2,2))

## No - npreg
plot(density(original[type=="No",]$npreg),col="blue",xlim=c(0,16),ylim=c(0,0.25),main="NO - npreg")
lines(density(imputed.data.mice.rf[type=="1",]$npreg),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$npreg),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$npreg),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"), 
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

## No - glu
plot(density(original[type=="No",]$glu),col="blue",xlim=c(32,216),ylim=c(0,0.02),main="NO - glu")
lines(density(imputed.data.mice.rf[type=="1",]$glu),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$glu),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$glu),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

## No - bp
plot(density(original[type=="No",]$bp),col="blue",xlim=c(26,122),ylim=c(0,0.06),main="NO - bp")
lines(density(imputed.data.mice.rf[type=="1",]$bp),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$bp),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$bp),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)


## No - skin
plot(density(original[type=="No",]$skin),col="blue",xlim=c(0,72),ylim=c(0,0.042),main="NO - skin")
lines(density(imputed.data.mice.rf[type=="1",]$skin),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$skin),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$skin),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

par(mfrow=c(2,2))

## No - bmi
plot(density(original[type=="No",]$bmi),col="blue",xlim=c(11,55),ylim=c(0,0.065),main="NO - bmi")
lines(density(imputed.data.mice.rf[type=="1",]$bmi),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$bmi),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$bmi),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)


## No - ped
plot(density(original[type=="No",]$ped),col="blue",xlim=c(0,2.0),ylim=c(0,2.1),main="NO - ped")
lines(density(imputed.data.mice.rf[type=="1",]$ped),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$ped),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$ped),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)


## No - age
plot(density(original[type=="No",]$age),col="blue",xlim=c(14,70),ylim=c(0,0.082),main="NO - age")
lines(density(imputed.data.mice.rf[type=="1",]$age),col="red")
lines(density(imputed.data.mice.pmm[type=="1",]$age),col="brown")
lines(density(imputed.data.mice.mean[type=="1",]$age),col="green")
legend("topright", c("Original","Mice rf","Mice pmm","Mice mean"),
       lty = c(1,1,1,1), col = c("blue","red","brown","green"), cex = 0.55)

```

A pesar que de acuerdo al RMSE, parecen haber diferencias entre los métodos imputados, en los gráficos de densidad se observa que las diferencias entre métodos no es drástica.

---

#4. Considere el conjunto de datos msleep del paquete ggplot2. Realice un análisis descriptivo, aplique las técnicas de imputaciones de los paquetes mostrados en clase u otros que considere conveniente.

---

##Carga de los datos

La data contiene 11 variables catergóricas y númericas de  83 observaciones.

```{r, message=FALSE, warning=FALSE, include=TRUE}
data("msleep",package = "ggplot2")
msleep=data.table(msleep)
dim(msleep)
summary(msleep)
```

##Verificación de valores perdidos

```{r, message=FALSE, warning=FALSE, include=TRUE}
sapply(msleep, function(x) sum(is.na(x)))
vis_miss(msleep)
```

Se observa que 5 de 11 variables tienen valores perdidos.Las variables que contienen valores perdidos son:

* Vore : 8.43%
* Conservatio: 34.94%
* Sleep_rem: 26.51%
* spleep_cycle: 61.45%
* brainwt: 32.53%

En general, la data tiene el 14.9% de los registros con valores perdidos. A continuación, se presenta las relaciones de los registros en missing con las 5 variables que las contienen:


```{r, message=FALSE, warning=FALSE, include=TRUE}
# Otro
mice_plot <- aggr(msleep, col=c('navyblue','yellow'),
                  numbers=TRUE, sortVars=TRUE,
                  labels=names(msleep), cex.axis=.7,
                  gap=3, ylab=c("Missing data","Pattern"))

```

##Análisis descriptivo

Antes de empezar con el análisis descriptivo, se modifica las variables que son tipo "character" a "factor":

```{r, message=FALSE, warning=FALSE, include=TRUE}
## Estructura de la base de datos
str(msleep)
# cambiemos los character a factor
msleep[,name:= as.factor(name)]
msleep[,genus:= as.factor(genus)]
msleep[,vore:= as.factor(vore)]
msleep[,order:= as.factor(order)]
msleep[,conservation:= as.factor(conservation)]
str(msleep)
```

**Gráficos de boxplot de las variables según "Sleep Total" **

Se puede observar que las medias de horas de sueño (sleep_total) varían según el tipo de alimentación de los mamíferos, vemos que los carnívoros, hervívoros y omnívoros tienen una media de 11 horas de sueño y aquellos que comen insectos tienen una media de 18 horas de sueño. 

```{r, message=FALSE, warning=FALSE, include=TRUE}
# Gráfico boxplot de Vore con Sleep Total

p1=msleep %>%
  ggplot(aes(vore,sleep_total,color=vore)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  labs(y = "Sleep Total", x = "Vore") +
  ggtitle("Sleep total con Vore")

# Gráfico boxplot de Conservation con Sleep Total

p2=msleep %>%
  ggplot(aes(conservation,sleep_total,color=conservation)) +
  geom_boxplot() +
  theme(legend.position = "none") +
  labs(y = "Sleep Total", x = "Vore") +
  ggtitle("Sleep total con Conservation")

# Sleep rem con Sleep total

p3=msleep %>%
  ggplot(aes(sleep_rem, sleep_total)) +
  geom_miss_point()+
  labs(x = "Sleep rem", y = "Sleep total") +
  ggtitle("Sleep total con Sleep rem")

# Sleep cycle con Sleep total

p4=msleep %>%
  ggplot(aes(sleep_cycle, sleep_total)) +
  geom_miss_point()+
  labs(x = "Sleep cycle", y = "Sleep total") +
  ggtitle("Sleep total con Sleep cycle")

# Awake con Sleep total

p5=msleep %>%
  ggplot(aes(awake, sleep_total)) +
  geom_miss_point()+
  labs(x = "Awake", y = "Sleep total") +
  ggtitle("Sleep total con Awake")

# Brainwt con Sleep total

p6=msleep %>%
  ggplot(aes(brainwt, sleep_total)) +
  geom_miss_point()+
  labs(x = "Brain weigth", y = "Sleep total") +
  ggtitle("Sleep total con Brain weigth")

# bodywt con Sleep total

p7=msleep %>%
  ggplot(aes(bodywt, sleep_total)) +
  geom_miss_point()+
  labs(x = "Body weigth", y = "Sleep total") +
  ggtitle("Sleep total con Body weigth")


grid.arrange(p1,p2,p3,p4,p5,p6,p7,nrow=4)
```

El movimiento de los ojos al dormir "rem_sleep" y "sleep_total" tienen correlación positiva que indica que a mayor duración del sueño mayor movimiento de los ojos.
La correlación negativa de -1 entre sleep_total y awake indica indica que los datos en esas dos columnas están bien registrados ya que las dos variables son complementarias.
La correlación entre log("bodywt") y "sleep_total" es negativa indicando que a mayor peso menores horas de sueño; de igual forma a mayor peso del cerebro "brainwt" menos horas de sueño. El peso del cuerpo "bodywt" está relacionado con el peso del cerebro "brainwt".

**Cuadro de medias de variables antes de la imputación**

A continuación se presenta las medias de las variables numéricas según "Vore" y "Conservation" y además las medias de las 3 variables numéricas que contienen missing:

```{r, message=FALSE, warning=FALSE, include=TRUE}
descrip1=data.frame(msleep %>%
  filter(is.na(vore)==FALSE) %>%
  group_by(vore) %>%
  summarise(mean.sleep.total=mean(sleep_total),
            mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
            mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
            mean.brain.wt=mean(brainwt,na.rm = TRUE),
            mean.awake=mean(awake),
            mean.body.wt=mean(bodywt)))

descrip2=data.frame(msleep %>%
  filter(is.na(conservation)==FALSE) %>%
  group_by(conservation) %>%
  summarise(mean.sleep.total=mean(sleep_total),
            mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
            mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
            mean.brain.wt=mean(brainwt,na.rm = TRUE),
            mean.awake=mean(awake),
            mean.body.wt=mean(bodywt)))

descrip3=msleep %>%
  summarise(mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
            mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
            mean.brain.wt=mean(brainwt,na.rm = TRUE))

descrip1; descrip2; descrip3

```

##Imputación

Se realizan las imputaciones utlizando los paquetes VIM y mice. En el caso de VIM se utilizó el método kNN para imputar las variables categóricas y robust para las numéricas.

```{r, message=FALSE, warning=FALSE, include=TRUE}
#VIM - Knn
imp4.1.1 <- kNN(msleep,k=10)
data4.imp4.1.1<-cbind(imp4.1.1[1:5],msleep[,6:11],imp4.1.1[12:22])
imp4.1.2 <- irmi(data4.imp4.1.1[,6:11],eps=10,maxit=10, robust=TRUE)
imp.data.knn<-cbind(imp4.1.1[1:5],imp4.1.2[,1:6],imp4.1.1[12:22],imp4.1.2[7:9])

#Mice
init = mice(msleep , maxit=0)
meth = init$method
predM = init$predictorMatrix

meth[c("vore")]="polyreg"
meth[c("conservation")]="polyreg"
meth[c("sleep_rem")]="pmm"
meth[c("sleep_cycle")]="pmm"
meth[c("brainwt")]="rf" 

imp.mice = mice(msleep, method=meth , predictorMatrix=predM , m=5,maxit = 5,seed = 123,print=FALSE)

```

**Evaluación de imputaciones**

En el striplot de abajo se observa que los datos imputados se alinean a los datos originales con el paquete mice.

```{r, warning=FALSE, include=TRUE}
library(lattice)
stripplot(imp.mice, pch = 20, cex = 1)
```

En el siguiente gráfico se indica las imputaciones que se hicieron con irmi del paquete VIM en las columnas "vore" y "conservation". De manera general se puede ver que las imputaciones de color marrón están acorde a los gráficos de dispersión originales. Se observan pequeños desplazamientos de las medianas una vez que han sido imputados los datos, pero que no alteran las distribuciones originales.

```{r, message=FALSE, warning=FALSE, include=TRUE}
library(VIM)
library(gridExtra)
vars<-c("sleep_cycle","brainwt","sleep_rem","sleep_cycle_imp","brainwt_imp","sleep_rem_imp")
data4.imp.g<-imp.data.knn[,c(7,8,10,17:19)]
data4.imp.g<-cbind(log(data4.imp.g[,c(1:3)]),imp.data.knn[,17:19])
# Building marginplot matrix
marginmatrix(data4.imp.g, 
              delimiter = "_imp", 
              alpha=0.9,
             size = 5)
```


**Comparación de medias de las variables con imputación y sin imputación**

Se realiza una verificación adicional de las imputaciones con las medias de las variables numéricas imputadas clasificadas por "vore" y "conservation". Se espera que mantengan consistencia con la data original; es decir se analiza si las imputaciones de las variables categóricas  no modifican las distribuciones de las variables numéricas. En la parte inferior se muestran los resultados. 


```{r, message=FALSE, warning=FALSE, include=TRUE}
imp.data.knn=imp.data.knn[,1:11]
# Medias con variables imputadas con kNN e irmi
descrip1.imp=data.frame(imp.data.knn %>%
                          group_by(vore) %>%
                          summarise(mean.sleep.total=mean(sleep_total),
                                    mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
                                    mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
                                    mean.brain.wt=mean(brainwt,na.rm = TRUE),
                                    mean.awake=mean(awake),
                                    mean.body.wt=mean(bodywt)))

descrip2.imp=data.frame(imp.data.knn %>%
                          group_by(conservation) %>%
                          summarise(mean.sleep.total=mean(sleep_total),
                                    mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
                                    mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
                                    mean.brain.wt=mean(brainwt,na.rm = TRUE),
                                    mean.awake=mean(awake),
                                    mean.body.wt=mean(bodywt)))

descrip3.imp=imp.data.knn %>%
  summarise(mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
            mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
            mean.brain.wt=mean(brainwt,na.rm = TRUE))
```


```{r, message=FALSE, warning=FALSE, include=TRUE}
imp.data.mice= mice::complete(imp.mice)

descrip1.imp.mice=data.frame(imp.data.mice %>%
                          group_by(vore) %>%
                          summarise(mean.sleep.total=mean(sleep_total),
                                    mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
                                    mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
                                    mean.brain.wt=mean(brainwt,na.rm = TRUE),
                                    mean.awake=mean(awake),
                                    mean.body.wt=mean(bodywt)))

descrip2.imp.mice=data.frame(imp.data.mice %>%
                          group_by(conservation) %>%
                          summarise(mean.sleep.total=mean(sleep_total),
                                    mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
                                    mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
                                    mean.brain.wt=mean(brainwt,na.rm = TRUE),
                                    mean.awake=mean(awake),
                                    mean.body.wt=mean(bodywt)))


descrip3.imp.mice=imp.data.mice %>%
  summarise(mean.sleep.rem=mean(sleep_rem,na.rm=TRUE),
            mean.sleep.cycle=mean(sleep_cycle,na.rm = TRUE),
            mean.brain.wt=mean(brainwt,na.rm = TRUE))
```

En el caso de la variable categórica "vore", los resu ltados de los dos métodos de  imputación se aproximan a la data original; sin embargo la imputación por "mice" se ajusta mejor a la distribución original.

```{r, message=FALSE, warning=FALSE, include=TRUE}
list(sin_imputar=descrip1,imputados_irmi=descrip1.imp,imputados_mice=descrip1.imp.mice)
```

Se revisa si la imputación de la variable categórica conservation no modifica la distribución de las variables numéricas. Para esto se verifica las medias según la variable "conservation". Los resultados de las medias obtenidas con la imputación "irmi" están más cerca de la data original.
```{r, message=FALSE, warning=FALSE, include=TRUE}
list(sin_imputar=descrip2,imputados_irmi=descrip2.imp,imputados_mice=descrip2.imp.mice)
```

Finalmente se muestran las medias de las variables. Vemos que los valores de las medias obtenidas con mice se encuentran más cerca de la media de la data sin imputar. 

```{r, message=FALSE, warning=FALSE, include=TRUE}
list(sin_imputar=descrip3,imputados_irmi=descrip3.imp,imputados_mice=descrip3.imp.mice)
```

---

#5. Considere el conjunto de datos (UnitedNations) que se encuentra en la siguiente dirección https://goo.gl/iR3diF y la descripción de los datos se encuentra en https://goo.gl/RetP3J. Realicé un análisis descriptivo y haga uso de diferentes paquetes en R para imputar los datos y compare los resultados.

---

**Cargar la data**

Se carga la base de datos desde el sitio web proporcionado.
```{r, message=FALSE, warning=FALSE, include=TRUE}
data_UN <- read.csv(url("https://socialsciences.mcmaster.ca/jfox/Books/Applied-Regression-2E/datasets/UnitedNations.txt"),sep=" ")
data_UN$region<-as.factor(data_UN$region)
```

La base de datos de "Indicadores Sociales de las Naciones Unidas" contiene 207 observaciones de 13 variables. "Region" es la única variable categórica, las demás variables son numéricas. Las variables contienen información relacionada a salud, educación y situación económica de hombres y mujeres en países de los cinco continentes. Se puede verificar que hay columnas que presentan missing values. Antes de procecer con la imputación de valores se realizará un análisis descriptivo de la información mediante boxplots de todas las variables por con la variable region.

```{r, message=FALSE, warning=FALSE, include=TRUE}
dim(data_UN)
summary(data_UN)
```


**Análisis descriptivo**

Los boxplot por región permiten visualizar: 

* Africa.- de manera general muestra los peores indicadores de salud, educación y economía. La tasa fertilidad es superior a los cinco hijos por cada mujer mientras Europa apenas supera un hijo por mujer. Menos del 20% de las mujeres tienen acceso a anticonceptivos mientras en América 50% lo tienen. La expectativa de vida es de 50 años, en cambio en  Europa supera los 80 años. Así mismo la mortalidad infantil es de cerca del 9% de los nacimientos. El PIB es más bajo a pesar de que son el continente que tiene mayor proporción de personas trabajando.
* Asia.- se puede mencionar que la tasa de natalidad, el acceso a anticoncentivos, mortalidad infantil y analfabetismo tienen mayor dispersión que Europa, América y Ocenanía lo que es una señal de inequidad en salud y educación en ese continente.
* Europa.- se puede resaltar que tiene la más del alta esperanza de vida y baja mortalidad infantil, mejor nivel de educación, menor tasa de analfabetismo y un pib per cápita mas alto. Un punto que llama la atención es el continente con menor proporción de personas que desempeñan una actividad económica.

```{r, message=FALSE, warning=FALSE, include=TRUE}
library(graphics)
par(mfrow=c(4,3), mar=c(2,2,2,2))
boxplot(tfr  ~ region, data=data_UN, main = "tfr (fertility)", col = "lightpink3",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(contraception   ~ region, data=data_UN, main = "contraception", col = "lightpink3",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(lifeMale  ~ region, data=data_UN, main = "lifeMale", col = "lightpink3",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(lifeFemale  ~ region, data=data_UN, main = "lifeFemale", col = "lightpink3",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(infantMortality  ~ region, data=data_UN, main = "infantMortality", col = "lightpink3",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(educationMale  ~ region, data=data_UN, main = "educMale", col = "lightskyblue4",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(educationFemale  ~ region, data=data_UN, main = "educationFemale", col = "lightskyblue4",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(illiteracyMale  ~ region, data=data_UN, main = "Illiteracy male", col = "lightskyblue4",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(illiteracyFemale  ~ region, data=data_UN, main = "Illiteracy female", col = "lightskyblue4",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(GDPperCapita  ~ region, data=data_UN, main = "GDP per capita", col = "orange1",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(economicActivityMale  ~ region, data=data_UN, main = "Econ activity - region", col = "orange1",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
boxplot(economicActivityFemale  ~ region, data=data_UN, main = "Econ female", col = "orange1",cex.main=0.85,cex.lab=0.45,cex.axis=0.85)
```


**Análisis de missing values**
Al revisar la base de datos se tienen 168 filas con 551 missing values. Esto reflejaría un problema al momento de correr una regresión con todas las variables ya que no se tomarían en cuenta el 20% de los datos.
```{r, include=TRUE}
ok <- complete.cases(data_UN)
sum(!ok)
table(is.na(data_UN))
```

262 missing values corresponden a "educationMale" y "educationFemale". Le  siguen contraception con 63 missing values.
```{r 5.3.1, message=FALSE, warning=FALSE, include=TRUE}
c5<-apply(is.na(data_UN),2,sum)
as.matrix(c5[c5>0])
```

En este gráfico se corrobora que el 20.5% delos datos son missing values y  que el 63.29% de las variables "educationMale" y "educationFemale" son NA.

```{r, message=FALSE, warning=FALSE, include=TRUE}
vis_miss(data_UN)
```
    
Este gráfico siguiente corrobora que las variables con mayor porcentaje de missing "educationMale" y "educationFemale." La región con mayor porcentaje de missing values en las variables de Educación es Oceanía con el 80%, África con 70%, 60% en América,  De realizar una regresión lineal, la region no sería tomada en cuenta para realizar el modelo. De ahí el poder realizar una imputación adecuada.

```{r, include=TRUE}
gg_miss_fct(x = data_UN, fct = region)+ labs(title = "NA en United Nations Social Indicators")
```

**Imputación de valores**
Se realizan imputaciones por los paquetes: Mice y VIM:

```{r, include=TRUE}
# Imputación mice
init = mice(data_UN , maxit=0,print=F)
pred <- init$pred
imp.mice <- mice(data_UN, pred=pred,m=10, maxit=10, 
                 meth=c('norm'), 
                 seed=99, diag=FALSE, print=FALSE)
imp.data.mice<-(as.data.frame(mice::complete(imp.mice)))
```

```{r, include=TRUE}
imp.data.irmi <- irmi(data_UN[,1:13],eps=10,maxit=10, robust=TRUE)
imp.data.irmi<-as.data.frame(imp.data.irmi)
```

A continuación, con los resultados de mice podemos visualizar si las gráficas de densidad de los datos originales y los datos ingresados están cerca: azul son los dato originales, rojo las imputaciones. En el caso de la variable "GDPperCápita" las iteraciones no se acercan a la distribución por lo cual más adelante se analizaremos las distribuciones de estas variables por región.

```{r, include=TRUE}
lattice::densityplot(imp.mice,layout = c(4, 3),cex=0.5,cex.axis=0.5,cex.lab=0.5,cex.main=0.5,cex.sub=0.5) # groups = region,
```

Se analiza la variación en las medias de cada variable antes y luego de las imputaciones con mice e irmi. La variación porcentual es similar para los 2 métodos de imputación importante en tfr (-13%), infantMortality (-9%,-12%), GDPperCapita(-20%,-23%), illiteracyFemale (-14%,-19%). Mas adelante se verifica si para el caso de GDPperCapita las distribuciones por región de las imputaciones se aproximan a la original.

```{r, include=TRUE}

mean.data<-round(as.matrix(sapply((na.omit(data_UN[,2:13])),mean)),2)
mean.mice<-round(as.matrix(sapply((imp.data.mice[,2:13]),mean)),2)
mean.irmi<-round(as.matrix(sapply((imp.data.irmi[,2:13]),mean)),2)
mean.data.t<-cbind(mean.data,mean.mice,mean.irmi)

colnames(mean.data.t)<-c("mean.data","mean.mice","mean.irmi") 
mean.data.t<-as.data.frame(mean.data.t)
mean.data.t$Dif.mi  <-round(((mean.data.t$mean.data-mean.data.t$mean.mice)/mean.data.t$mean.data),2)
mean.data.t$Dif.ir  <-round(((mean.data.t$mean.data-mean.data.t$mean.irmi)/mean.data.t$mean.data),2)
rownames(mean.data.t)<-c("tfr","contracep","educMale","educFem","lifeMal","lifeFem","InfantMort","GDPperC","economicMal","economicFem","illitMale","illitFem")
mean.data.t
```
Con el fin de verificar si las variaciones presentadas se deben a que las distribuciones de datos imputados no corresponden con la data original se realizan los siguientes gráficos donde se observa los métidos de imputación mice e irmi son los que más se asemejan a la data original las imputaciones de dos variables "GDPperCapita" y "EducationFemale"" por región .
La distribuciones por el método de imputación "imputeR" de la variable EducationFemale por "region" no se ajustan en África y Oceanía a la distribución de la data original.

```{r, message=FALSE, warning=FALSE, include=TRUE}
library(ggplot2)
library(ggpubr)
# data5
imp5.1.mice<-imp.data.mice[,1:13]
imp5.3.irmi<-imp.data.irmi[,1:13]

imp5.1.mice$method<-c("mice")
imp5.3.irmi$method<-c("irmi")
data_UN$method<-c("original")
data.imp.t<-rbind(data_UN,imp5.1.mice,imp5.3.irmi)

Africa<-data.imp.t[data.imp.t$region=="Africa",(1:14)]
America<-data.imp.t[data.imp.t$region=="America",(1:14)]
Asia<-data.imp.t[data.imp.t$region=="Asia",(1:14)]
Europa<-data.imp.t[data.imp.t$region=="Europe",(1:14)]
Oceania<-data.imp.t[data.imp.t$region=="Oceania",(1:14)]

p1<-ggplot(Africa, aes(x=GDPperCapita, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="GDPperCapita Africa", x="GDPperCapita")+xlim(0,43000)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p2<-ggplot(America, aes(x=GDPperCapita, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="GDPperCapita America", x="GDPperCapita")+xlim(0,43000)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p3<-ggplot(Asia, aes(x=GDPperCapita, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="GDPperCapita Asia", x="GDPperCapita")+xlim(0,43000)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p4<-ggplot(Europa, aes(x=GDPperCapita, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="GDPperCapita Europa", x="GDPperCapita")+xlim(0,60000)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p5<-ggplot(Oceania, aes(x=GDPperCapita, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="GDPperCapita Oceanía", x="GDPperCapita")+xlim(0,43000)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

ggarrange(p1, p2, p3, p4, p5, ncol = 2, nrow = 3)

```

```{r, message=FALSE, warning=FALSE, include=TRUE}

p1<-ggplot(Africa, aes(educationFemale, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="educationFemale África", "educationFemale")+xlim(0,20)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p2<-ggplot(America, aes(educationFemale, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="educationFemale América", "educationFemale")+xlim(0,20)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p3<-ggplot(Asia, aes(educationFemale, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="educationFemale Asia", "educationFemale")+xlim(0,20)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p4<-ggplot(Europa, aes(educationFemale, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="educationFemale Europa", "educationFemale")+xlim(0,20)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

p5<-ggplot(Oceania, aes(educationFemale, fill=method)) + geom_density(alpha=0.2) + 
  labs(title="educationFemale Oceanía", "educationFemale")+xlim(0,20)+theme_update(text = element_text(size=7))+ theme(plot.margin = unit(c(0.4,0.4,0.4,0.4), "lines"))

ggarrange(p1, p2, p3, p4, p5, ncol = 2, nrow = 3)
```


**Comparación de modelos realizados con data original e imputada**
En la parte inferior se modela la variable "infantMortality". Se realizan regresiones lineales con la data original y con la data que incorpora las imputaciones con el fin de verificar que las imputaciones no cambien las estimaciones que se obtendrían con la data original. 

Antes de evaluar los resultados obtenidos cabe mencionar que la data original únicamente tiene 39 filas completas. 

El signo de los coeficientes de regresión se mantiene en las regresiones realizadas con los datos imputados por los distintos métodos, solo cambia para Oceanía.

```{r, message=FALSE, warning=FALSE, include=TRUE}
# lm con data original sin NA
lm.orig<-lm(log(infantMortality)~as.factor(region)+educationFemale+log(GDPperCapita),data=na.omit(data_UN))

# lm con data imputada con mice
lm.mice<-lm(log(infantMortality)~as.factor(region)+educationFemale+log(GDPperCapita),data=imp.data.mice)

# lm con data imputada con irmi
lm.irmi<-lm(log(infantMortality)~as.factor(region)+educationFemale+log(GDPperCapita),data=imp.data.irmi)

# Coeficientes de los modelos
coef_orig=coef(lm.orig)
coef_mice=coef(lm.mice)
coef_irmi=coef(lm.irmi)

list(coef_orig=coef_orig,coef_mice=coef_mice,coef_irmi=coef_irmi)
```

